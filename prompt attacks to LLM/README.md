## Домашнее задание:
# Промпт-атаки на большие языковые модели (LLM)

## Задача:
**1**. Вникнуть в тематику, разобраться с тем чем GenAI (в частности LLM) отличается от классических алгоритмов AI. Разобраться в уязвимостях специфичных для GenAI, как на этапе обучения, так и на этапе эксплуатации модели.

**2**. Подготовить список актуальных промпт-атак, реализуемых через окно диалога.  Отдельное внимание уделить промпт-атакам в части кибербезопасности (КБ). «Использование LLM модели как инструмента подготовки кибератаки» - генерация вредоносного кода, социальная инженерия, фишинг и т.п. Поискать в открытых источниках и научных публикациях.

**3**. Попробовать провести промпт-атаку на LLM модели в свободном доступе. Оценить успешность атаки.

## 1. Различия между AI, ML, LLM, and Generative AI
### 1.1 Исскуственный интеллект - Artificial intelligence - AI
![](AI.jpg)
**Искусственный интеллект** относится к области компьютерных наук, которая занимается разработкой компьютерных систем, способных выполнять задачи, обычно требующие человеческого интеллекта, такие как распознавание речи, обработка естественного языка (NLP), генерация и перевод текста, видео, звука и изображений, принятие решений, планирование и многое другое.

**AI**, в общем, относится к разработке интеллектуальных систем, которые могут имитировать поведение человека и процессы принятия решений. Он включает в себя методы и подходы, позволяющие машинам выполнять задачи, анализировать визуальные и текстовые данные, а также реагировать на окружающую среду или адаптироваться к ней. Одним из **ключевых преимуществ искусственного интеллекта** является его способность обрабатывать большие объемы данных и находить в них закономерности.

### 1.2 Генеративный и Дискриминационный AI
![](Discriminative_vs_Generative_AI.png)
**Дискриминирующий и порождающий ИИ** - это два разных подхода к созданию систем искусственного интеллекта. Дискриминирующий ИИ фокусируется на изучении границ, которые разделяют различные классы или категории в обучающих данных. Эти модели предназначены не для создания новых выборок, а скорее для классификации или маркировки входных данных в зависимости от того, к какому классу они принадлежат. Дискриминационные модели обучаются выявлять закономерности и особенности, характерные для каждого класса, и делать прогнозы на основе этих закономерностей.
В отличие от дискриминативного ИИ, **генеративный ИИ** фокусируется на построении моделей, которые могут генерировать новые данные, аналогичные данным обучения, которые он видел. Генеративные модели изучают распределение вероятностей, лежащее в основе обучающих данных, и затем могут генерировать новые выборки из этого изученного распределения.

### 1.3 AI, ML, DL
![](AI_ML_DL.webp)
**Машинное обучение** - это специфическая область применения ИИ, которая направлена на то, чтобы дать системам возможность учиться и совершенствоваться на основе опыта без явного программирования. Алгоритмы ML используются для обучения моделей ИИ путем предоставления им наборов данных, содержащих помеченные примеры или исторические данные. Затем модель изучает базовые закономерности в обучающих данных, что позволяет ей делать точные прогнозы или принимать решения на основе новых ранее неизвестных данных.

В зависимости от того, как модели обучаются, **ML можно разделить на три типа**:

**1)** **Контролируемое обучение** (Supervised learning), при котором каждая выборка данных должна иметь метку, указывающую на правильный результат. Модель обучается на основе структурированных данных с метками, таких как CSV-файлы, корректируя свои внутренние параметры в зависимости от ошибки, с которой она угадывает результат. Контролируемое обучение на сегодняшний день является наиболее часто используемым видом обучения в области классификации изображений, распознавания голоса и языка, численного прогнозирования и многого другого.
**2)** **неконтролируемое обучение** (Unsupervised learning,) - предполагает работу с данными, как правило, неструктурированными, без меток. Обучение без учителя использует кластеризацию и другие методы для понимания базовой структуры данных, выявления закономерностей и выявления аномалий, мошенничества, анализа социальных сетей, сегментации рынка и обучения под руководством учителя.
**3)** **Обучение с подкреплением** (Reinforcement learning) основано на том, что агент должен вести себя в среде и учиться, выполняя определенные действия, наблюдая за результатами / вознаграждениями и соответствующим образом приспосабливаясь. Он использовался для игры в сложные игры, такие как "Погоня" и "Го" (где он победил чемпиона мира). Он также используется в автономных транспортных средствах, робототехнике и финансовой торговле


**Глубокое обучение** - это техника машинного обучения, вдохновленная тем, как человеческий мозг фильтрует информацию, в основном это обучение на примерах. Это помогает компьютерной модели фильтровать входные данные по слоям для прогнозирования и классификации информации.


### 1.4 GenAI & LLM
![](LLM.jpg)
Генеративный ИИ - это широкое понятие, охватывающее различные формы генерации контента, в то время как LLM - это конкретное применение генеративного ИИ. **Большие языковые модели** (Large language models) служат базовыми моделями, обеспечивая основу для широкого спектра задач обработки естественного языка (natural language processing - NLP). Генеративный ИИ может выполнять целый ряд задач, выходящих за рамки создания языка, включая создание изображений и видео, создание музыкальных композиций и многое другое. Большие языковые модели, как одно из конкретных применений генеративного ИИ, специально разработаны для задач, связанных с генерацией и пониманием естественного языка.

**Большие языковые модели работают с использованием обширных наборов данных** для изучения закономерностей и отношений между словами и фразами. Они были обучены работе с огромными объемами текстовых данных, чтобы изучить статистические закономерности, грамматику и семантику человеческого языка. Этот огромный объем текста может быть взят из Интернета, книг и других источников, чтобы развить глубокое понимание человеческого языка.

LLM может взять заданные входные данные (предложение или подсказку) и сгенерировать ответ: связные и контекстуально соответствующие предложения или даже абзацы, основанные на заданной подсказке или вводных данных. Модель использует различные методы, включая механизмы внимания, преобразователи и нейронные сети, для обработки входных данных и генерации выходных данных, которые должны быть последовательными и соответствовать контексту.

Как генеративный ИИ, так и большие языковые модели предполагают использование глубокого обучения и нейронных сетей. В то время как генеративный ИИ нацелен на создание оригинального контента в различных областях, большие языковые модели сосредоточены на задачах, связанных с языком, и превосходно понимают и генерируют текст, похожий на человеческий.

## 2. Уязвимости специичные для GenAI

Генеративные модели искусственного интеллекта (GenAI) могут сталкиваться с различными уязвимостями как на этапе обучения, так и на этапе эксплуатации. Вот некоторые из них:

### 2.1 Уязвимости на этапе обучения

1. Предвзятость данных:
   - Если обучающие данные содержат предвзятости или стереотипы, модель может унаследовать и даже усугубить эти предвзятости в своих выводах и генерируемом контенте.

2. Неполнота данных:
   - Недостаточное или нерепрезентативное количество данных может привести к плохой обобщающей способности модели, что делает её менее эффективной для решения реальных задач.

3. Атаки на данные (Data Poisoning):
   - Злоумышленники могут попытаться внедрить вредоносные или манипулятивные данные в обучающий набор, что может исказить поведение модели.

4. Отсутствие прозрачности:
   - Модели глубокого обучения часто являются "черными ящиками", что затрудняет понимание того, как они принимают решения, и может скрыть потенциальные уязвимости.

5. Проблемы с масштабируемостью:
   - Обучение больших моделей требует значительных вычислительных ресурсов, что может привести к уязвимостям в инфраструктуре, например, к перегрузке серверов.

### 2.2 Уязвимости на этапе эксплуатации

1. Генерация вредоносного контента:
   - GenAI может случайно или намеренно генерировать дезинформацию, ненавистнические высказывания или другой вредоносный контент.

2. Атаки через ввод (Prompt Injection):
   - Злоумышленники могут манипулировать вводом, чтобы заставить модель генерировать нежелательный или опасный контент.

3. Утечка конфиденциальной информации:
   - Модели могут запоминать и воспроизводить конфиденциальную информацию из обучающих данных, что может привести к утечке личных данных.

4. Неустойчивость к манипуляциям:
   - Модели могут быть уязвимы к изменениям в вводимых данных, что может привести к непредсказуемым результатам или ошибкам.

5. Зависимость от качества ввода:
   - Качество и точность выходных данных сильно зависят от качества входных данных; нечеткие или некорректные запросы могут привести к неправильным ответам.

6. Уязвимости в API:
   - Если GenAI используется через API, могут возникнуть проблемы с безопасностью, такие как недостаточная аутентификация или защита от DDoS-атак.

## 3. Актуальные промпт-атаки на LLM